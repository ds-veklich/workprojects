{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4690f846",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Импортируем-библиотеки-и-функции,-используемые-в-проекте\" data-toc-modified-id=\"Импортируем-библиотеки-и-функции,-используемые-в-проекте-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Импортируем библиотеки и функции, используемые в проекте</a></span></li><li><span><a href=\"#Загрузка-и-предварительный-анализ-данных\" data-toc-modified-id=\"Загрузка-и-предварительный-анализ-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Загрузка и предварительный анализ данных</a></span></li><li><span><a href=\"#Подготовка-данных-без-использования-BERT\" data-toc-modified-id=\"Подготовка-данных-без-использования-BERT-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Подготовка данных без использования BERT</a></span></li><li><span><a href=\"#Подготовка-данных-с-BERT\" data-toc-modified-id=\"Подготовка-данных-с-BERT-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Подготовка данных с BERT</a></span></li></ul></li><li><span><a href=\"#Обучение-ML-моделей\" data-toc-modified-id=\"Обучение-ML-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение ML-моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-ML-моделей-без-использования-BERT\" data-toc-modified-id=\"Обучение-ML-моделей-без-использования-BERT-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обучение ML-моделей без использования BERT</a></span></li><li><span><a href=\"#Обучение-ML-моделей-с-BERT\" data-toc-modified-id=\"Обучение-ML-моделей-с-BERT-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение ML-моделей с BERT</a></span></li></ul></li><li><span><a href=\"#Классификация-комментариев\" data-toc-modified-id=\"Классификация-комментариев-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Классификация комментариев</a></span><ul class=\"toc-item\"><li><span><a href=\"#Прогнозирование-ML-моделей-на-тестовых-выборках,-подготовленных-без-использования-BERT\" data-toc-modified-id=\"Прогнозирование-ML-моделей-на-тестовых-выборках,-подготовленных-без-использования-BERT-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Прогнозирование ML-моделей на тестовых выборках, подготовленных без использования BERT</a></span></li><li><span><a href=\"#Прогнозирование-ML-моделей-на-тестовых-выборках,-подготовленных-с-BERT\" data-toc-modified-id=\"Прогнозирование-ML-моделей-на-тестовых-выборках,-подготовленных-с-BERT-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Прогнозирование ML-моделей на тестовых выборках, подготовленных с BERT</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188293b",
   "metadata": {},
   "source": [
    "# Классификация комментариев для сервиса компании «BestService» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad07aa",
   "metadata": {},
   "source": [
    "Компания «BestService» предоставляет сервис по поиску клиентов для специалистов в разных областях. Клиенты сервиса оставляют свои комментарии с предложениями по работе сервиса и качеству оказываемых услуг. Компании необходим инструмент, который будет выявлять негативные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Необходимо построить ML-модель для классификации комментариев на позитивные и негативные. В компании есть набор данных с разметкой комментариев.\n",
    "\n",
    "Требования к ML-модели и данным:\n",
    "1. Качество прогнозирования оценивать по метрике F1, значение метрики на тестовой выборке должно быть не меньше 0.75.\n",
    "2. В рамках проекта подготовить обучающие и тестовые выборки для ML-моделей как с использованием предобученной модели нейронной сети BERT, так и без нее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dbcbd",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf2298",
   "metadata": {},
   "source": [
    "### Импортируем библиотеки и функции, используемые в проекте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7445b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import notebook, tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d9f6b",
   "metadata": {},
   "source": [
    "### Загрузка и предварительный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd453b",
   "metadata": {},
   "source": [
    "Прочитаем файл 'toxic_comments.csv' и сохраним его в переменной df_comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8526eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ca72f",
   "metadata": {},
   "source": [
    "Выведем на экран общую информацию и первые 5 строк датафрейма df_comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8c58c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.info()\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4ff86",
   "metadata": {},
   "source": [
    "**По результатам предварительного анализа можно сделать следующие выводы:**\n",
    "1. Датафрейм df_comments содержит 159571 строку и не содержит пропусков в данных. Каждая строка датафрейма содержит текст с комментарием и признак - положительный или отрицательный комментарий.\n",
    "2. В комментариях используется английский язык."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552f4cd",
   "metadata": {},
   "source": [
    "### Подготовка данных без использования BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484101b8",
   "metadata": {},
   "source": [
    "Произведем обработку текста комментариев (стемминг и очистку текста на английском языке) и сохраним результат в столбце 'stem_text' датафрейма df_comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4199d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#задаем размер батча\n",
    "batch_size = 1000\n",
    "#создаем текст разбитый на батчи\n",
    "text_batch = [df_comments.loc[i: i + batch_size-1, 'text'] for i in range(0, df_comments.shape[0], batch_size)]\n",
    "#создаем функцию для стемминга\n",
    "eng_stemmer = SnowballStemmer('english')\n",
    "\n",
    "def f_clear_text(f_text):\n",
    "    #функция для очистки текста\n",
    "    return ' '.join(re.sub(r'[^a-zA-Z| ]', ' ', f_text).split())\n",
    "\n",
    "def f_eng_stem_clear(f_text_batch):\n",
    "    #функция для стемминга текста на английском языке и его очистки от символов, кроме текста и одного пробела\n",
    "\n",
    "    #объединяем в одну строку текст батча (батч содержит список из batch_size строк)\n",
    "    merged_text = \"||||\".join(f_text_batch)\n",
    "    #производим стемминг текста и его очистку (остаются английские слова с одним пробелом между ними и разделитель)\n",
    "    stem_clear_text = f_clear_text(eng_stemmer.stem(merged_text))\n",
    "    #разделяем одну строку на список строк (обратно после стемминга и очистки)\n",
    "    list_txt = stem_clear_text.split('||||')\n",
    "\n",
    "    return list_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a34229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 160/160 [02:06<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       159571 non-null  object\n",
      " 1   toxic      159571 non-null  int64 \n",
      " 2   stem_text  159571 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Создаем столбец stem_text в датафрейме df_comments после стемминга и очистки столбца text\n",
    "list_text = Parallel(n_jobs=-1)(delayed(f_eng_stem_clear)(t) for t in tqdm(text_batch))\n",
    "stem_text = sum(list_text, [])\n",
    "df_comments['stem_text'] = stem_text\n",
    "df_comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811a60a",
   "metadata": {},
   "source": [
    "Разделим датафрейм df_comments на обучающую и тестовую выборки и сохраним корпусы выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1247fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение датафрейма после подготовки stem_text во внешний файл при необходимости\n",
    "#df_comments.to_csv('toxic_comments_stem.csv')\n",
    "#Загрузка датафрейма с stem_text из внешнего файла при необходимости\n",
    "#df_comments = pd.read_csv('toxic_comments_stem.csv')\n",
    "\n",
    "#Разделяем датафрейм на обучающую и тестовую выборки и сохраняем корпусы выборок\n",
    "df_train, df_test = train_test_split(df_comments, test_size=0.25)\n",
    "corpus_train = df_train['stem_text'].values\n",
    "corpus_test = df_test['stem_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44358d06",
   "metadata": {},
   "source": [
    "Создадим признаки для ML-моделей: для этого посчитаем TF-IDF для корпусов и выделим целевой признак, также выведем на экран размеры обучающей и тестовой выборок: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729a92da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dominikana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Загрузим стоп-слова\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a89d77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посчитаем TF-IDF для корпусов (признаки модели)\n",
    "tf_idf_vect = TfidfVectorizer(stop_words=stopwords).fit(corpus_train)\n",
    "features_train = tf_idf_vect.transform(corpus_train)\n",
    "features_test = tf_idf_vect.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb28c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделим целевой признак для обучающей и тестовой выборок\n",
    "target_train = df_train['toxic']\n",
    "target_test = df_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f6c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 142825)\n",
      "(119678,)\n",
      "(39893, 142825)\n",
      "(39893,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce1b3b",
   "metadata": {},
   "source": [
    "Посчитаем и выведем на экран баланс классов для обучающей и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ddf859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов для обучающей выборки:\n",
      " 0    0.898427\n",
      "1    0.101573\n",
      "Name: toxic, dtype: float64\n",
      "Баланс классов для тестовой выборки:\n",
      " 0    0.898002\n",
      "1    0.101998\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Баланс классов для обучающей выборки:\\n', target_train.value_counts(normalize=True))\n",
    "print('Баланс классов для тестовой выборки:\\n', target_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a39ac8",
   "metadata": {},
   "source": [
    "**Вывод:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e5719",
   "metadata": {},
   "source": [
    "1. Подготовлены без использования BERT обучающая и тестовая выборки для ML-моделей.\n",
    "2. Присутствует дисбаланс классов выборок (0 - 90%, 1 - 10%; считается, что классы сбалансированы при приблизительно равном распределении)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9443f8",
   "metadata": {},
   "source": [
    "### Подготовка данных с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ebe4cc",
   "metadata": {},
   "source": [
    "Для подготовки обучающей и тестовой выборок с использованием предобученной модели нейронной сети BERT необходимо: \n",
    "1. Произвести токенизацию каждого текста (текст разбивают на слова).\n",
    "2. Затем токены передать модели BERT, которая переведёт их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются векторы заданной длины (embeddings, «эмбеддинги»).\n",
    "2. Затем выделить целевой признак и произвести разделение выборок на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bcd56",
   "metadata": {},
   "source": [
    "Преобразование 1000 строк токенов с помощью BERT в эмбеддинги на персональном компьютере осуществляется в среднем 45 минут. Таким образом, создание эмбеддингов для всех строк датафрейма df_comments (159571 строка) с помощью BERT составит в среднем 7180 минут или около 5 суток.<br>\n",
    "**Поэтому, в целях экономии времени на выполнение проекта выберем случайные 10000 строк из всей выборки, создадим для них эмбеддинги и сохраним их в отдельных файлах** ('features_bert10000.csv' - файл с эмбеддингами; 'comments_bert10000' - файл с целевым признаком).<br>\n",
    "В целях демонстарции работы алгоритма создания эмбеддингов выберем случайные 100 строк и создадим для них эмбеддинги.<br>\n",
    "Затем, для подготовки выборки на 10000 строк загрузим эмбеддинги и целевой признак из ранее сохраненных файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80ce7335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EngBERT/pytorch_model.bin were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#Выборка случайной части данных датафрейма для обработки моделью нейронной сети BERT\n",
    "df_comments_bert = df_comments.sample(100).reset_index(drop=True)\n",
    "\n",
    "#Загрузка предобученной модели нейронной сети BERT\n",
    "config_bert = transformers.BertConfig.from_json_file('EngBERT/bert_config.json')\n",
    "model_bert = transformers.BertModel.from_pretrained('EngBERT/pytorch_model.bin', config=config_bert)\n",
    "tokenizer_bert = transformers.BertTokenizer(vocab_file='EngBERT/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d7c7095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded.shape: (100, 512) , attention_mask: (100, 512)\n"
     ]
    }
   ],
   "source": [
    "#Создание токенов для текста\n",
    "tokenized = df_comments_bert['text'].apply(\n",
    "    lambda x: tokenizer_bert.encode(x, add_special_tokens=True, truncation=True, padding='max_length', max_length=512))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "#Создание numpay array одинаковой длины для всех токенов и создание маски\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "print('padded.shape:', padded.shape, ', attention_mask:', attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "146e6600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80e7dae3bb048d4bc111c280d76bbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создание embeddings с помощью модели нейронной сети BERT\n",
    "batch_size = 50\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(0, padded.shape[0], batch_size)):\n",
    "    batch = torch.LongTensor(padded[i: i + batch_size])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[i: i + batch_size])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "    \n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "#Создаем признаки\n",
    "features_bert = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e85779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем ранее созданные выборки, в том числе с помощью BERT\n",
    "df_features_bert = pd.read_csv('features_bert10000.csv')\n",
    "df_comments_bert = pd.read_csv('comments_bert10000.csv')\n",
    "features_bert = df_features_bert.values\n",
    "\n",
    "#Разделяем признаки и целевой признак на обучающую и тестовую выборки\n",
    "target_bert = df_comments_bert['toxic']\n",
    "features_train_bert, features_test_bert, target_train_bert, target_test_bert = train_test_split(\n",
    "    features_bert, target_bert, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8acb9eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 768)\n",
      "(7500,)\n",
      "(2500, 768)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print(features_train_bert.shape)\n",
    "print(target_train_bert.shape)\n",
    "print(features_test_bert.shape)\n",
    "print(target_test_bert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460350c",
   "metadata": {},
   "source": [
    "Посчитаем и выведем на экран баланс классов для обучающей и тестовой выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bdb4ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов для обучающей выборки:\n",
      " 0    0.892933\n",
      "1    0.107067\n",
      "Name: toxic, dtype: float64\n",
      "Баланс классов для тестовой выборки:\n",
      " 0    0.9016\n",
      "1    0.0984\n",
      "Name: toxic, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Баланс классов для обучающей выборки:\\n', target_train_bert.value_counts(normalize=True))\n",
    "print('Баланс классов для тестовой выборки:\\n', target_test_bert.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05189bca",
   "metadata": {},
   "source": [
    "**Вывод:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70455f82",
   "metadata": {},
   "source": [
    "1. Подготовлены с использованием BERT обучающая и тестовая выборки для ML-моделей.\n",
    "2. Присутствует дисбаланс классов выборок (0 - 90%, 1 - 10%; считается, что классы сбалансированы при приблизительно равном распределении)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3104dc53",
   "metadata": {},
   "source": [
    "## Обучение ML-моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f1279",
   "metadata": {},
   "source": [
    "Создадим функцию для обучения одной из 4-х моделей («логистическая регрессия», «градиентный бустинг» библиотек XGBoost, LightGBM и CatBoost), расчета метрики F1 и оценки качества модели кросс-валидацией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e48e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_4ML_models_f1_cv(fv_features_train: pd.DataFrame, fv_target_train: pd.Series,\n",
    "                       fv_modelname: str, fv_cv=5, fv_max_estimators=400, fv_learning_rate=0.3,\n",
    "                       fv_scale_pos_weight=9, fv_class_weight='balanced'):\n",
    "    #функция для обучения одной из 4-х моделей, расчета метрики F1 и оценки качества модели кросс-валидацией\n",
    "    \n",
    "    #определим одну из 4-х моделей\n",
    "    if fv_modelname == 'XGBClassifier':\n",
    "        model = XGBClassifier(random_state=12345, n_estimators=fv_max_estimators,\n",
    "                              scale_pos_weight=fv_scale_pos_weight, learning_rate=fv_learning_rate,\n",
    "                              use_label_encoder=False, verbosity=0)\n",
    "    elif fv_modelname == 'LGBMClassifier':\n",
    "        model = LGBMClassifier(random_state=12345, n_estimators=fv_max_estimators,\n",
    "                               class_weight=fv_class_weight, learning_rate=fv_learning_rate)\n",
    "    elif fv_modelname == 'CatBoostClassifier':\n",
    "        model = CatBoostClassifier(random_state=12345, iterations=fv_max_estimators, learning_rate=fv_learning_rate,\n",
    "                                   verbose=False)\n",
    "    else:\n",
    "        model = LogisticRegression(random_state=12345, solver='liblinear', class_weight=fv_class_weight)\n",
    "    #вычислим метрику F1 с использованием кросс-валидации\n",
    "    scorer = make_scorer(f1_score, greater_is_better=True)\n",
    "    cv_f1score = cross_val_score(model, fv_features_train, fv_target_train, scoring=scorer, cv=fv_cv).mean()\n",
    "    \n",
    "    return cv_f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed960afa",
   "metadata": {},
   "source": [
    "### Обучение ML-моделей без использования BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0c2bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LinearRegression = 0.7494839910504182\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LinearRegression =', f_4ML_models_f1_cv(features_train, target_train, 'LogisticRegression', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7be3de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели XGBClassifier = 0.7542755763285248\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели XGBClassifier =', f_4ML_models_f1_cv(features_train, target_train, 'XGBClassifier', 2, 400, 0.3, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "871da97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LGBMClassifier = 0.7515774930090837\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LGBMClassifier =', f_4ML_models_f1_cv(features_train, target_train, 'LGBMClassifier', 2, 400, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8ee325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели CatBoostClassifier = 0.7388022924781674\n",
      "Wall time: 15min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели CatBoostClassifier =', f_4ML_models_f1_cv(features_train, target_train, 'CatBoostClassifier', 2, 400, 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7537f9",
   "metadata": {},
   "source": [
    "### Обучение ML-моделей с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54f62d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LinearRegression = 0.6401254987481935\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LinearRegression =', f_4ML_models_f1_cv(features_train_bert, target_train_bert, 'LogisticRegression', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46814464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели CatBoostClassifier = 0.5183258749666043\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели CatBoostClassifier =', f_4ML_models_f1_cv(features_train_bert, target_train_bert, 'CatBoostClassifier',\n",
    "                                                           2, 312, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c66b325",
   "metadata": {},
   "source": [
    "**Вывод:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f4a14",
   "metadata": {},
   "source": [
    "1. При обучении 4-х ML-моделей и оценке их качества кросс-валидацией с использованием выборок, подготовленных без использования BERT, достаточные для выполнения проекта значения метрики F1 показали 2 ML-модели - «градиентный бустинг» библиотек XGBoost и LightGBM (условие проекта: значение F1 не меньше 0.75).\n",
    "2. При обучении 2-х ML-моделей и оценке их качества кросс-валидацией с использованием выборок, подготовленных с использованием предобученной модели нейронной сети BERT, обе ML-модели показали низкие значения метрики F1 (менее 0.75)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4fa05",
   "metadata": {},
   "source": [
    "## Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7582b51",
   "metadata": {},
   "source": [
    "Создадим функцию для обучения одной из 4-х моделей («логистическая регрессия», «градиентный бустинг» библиотек XGBoost, LightGBM и CatBoost), расчета метрик F1 модели и констатной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdc784ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_5ML_models_f1(fv_features_train: pd.DataFrame, fv_target_train: pd.Series,\n",
    "                    fv_features_test: pd.DataFrame, fv_target_test: pd.Series,\n",
    "                    df_f1: pd.DataFrame, fv_bert:str, fv_modelname: str, fv_max_estimators=400, fv_learning_rate=0.3,\n",
    "                    fv_scale_pos_weight=9, fv_class_weight='balanced'):\n",
    "    #функция для обучения и расчета метрики F1 ML-моделей\n",
    "    \n",
    "    #определим одну из ML-моделей\n",
    "    if fv_modelname == 'XGBClassifier':\n",
    "        model = XGBClassifier(random_state=12345, n_estimators=fv_max_estimators,\n",
    "                              scale_pos_weight=fv_scale_pos_weight, learning_rate=fv_learning_rate,\n",
    "                              use_label_encoder=False, verbosity=0)\n",
    "    elif fv_modelname == 'LGBMClassifier':\n",
    "        model = LGBMClassifier(random_state=12345, n_estimators=fv_max_estimators,\n",
    "                               class_weight=fv_class_weight, learning_rate=fv_learning_rate)\n",
    "    elif fv_modelname == 'CatBoostClassifier':\n",
    "        model = CatBoostClassifier(random_state=12345, iterations=fv_max_estimators, learning_rate=fv_learning_rate,\n",
    "                                   custom_loss=['F1', 'AUC', 'Accuracy'])\n",
    "    elif fv_modelname == 'LogisticRegression':\n",
    "        model = LogisticRegression(random_state=12345, solver='liblinear', class_weight=fv_class_weight)\n",
    "    else:\n",
    "        #Константная модель\n",
    "        model = DummyClassifier(strategy='uniform')\n",
    "    #обучим модель\n",
    "    if fv_modelname == 'CatBoostClassifier':\n",
    "        model.fit(fv_features_train, fv_target_train, eval_set=(fv_features_test, fv_target_test),\n",
    "                  verbose=False, plot=True)\n",
    "    else:\n",
    "        model.fit(fv_features_train, fv_target_train)\n",
    "    #вычислим метрику F1\n",
    "    f1score = f1_score(fv_target_test, model.predict(fv_features_test))\n",
    "    #сохраним значения F1 для модели и константной модели\n",
    "    df_f1.loc[df_f1['Модель']==fv_modelname + fv_bert, 'F1-score'] = f1score\n",
    "    \n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122abb68",
   "metadata": {},
   "source": [
    "Создадим датафрейм df_f1 для хранения значений метрик F1 моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db56089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1 = pd.DataFrame(data=[['LogisticRegression без BERT', np.nan],\n",
    "                           ['XGBClassifier без BERT', np.nan],\n",
    "                           ['LGBMClassifier без BERT', np.nan],\n",
    "                           ['CatBoostClassifier без BERT', np.nan],\n",
    "                           ['Константная модель без BERT', np.nan],\n",
    "                           ['LogisticRegression с BERT', np.nan],\n",
    "                           ['CatBoostClassifier с BERT', np.nan],\n",
    "                           ['Константная модель с BERT', np.nan]],\n",
    "                     columns=['Модель', 'F1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e6be2",
   "metadata": {},
   "source": [
    "### Прогнозирование ML-моделей на тестовых выборках, подготовленных без использования BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df6562db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LinearRegression = 0.7542610571736785\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LinearRegression =', f_5ML_models_f1(features_train, target_train, features_test, target_test,\n",
    "                                                      df_f1, ' без BERT', 'LogisticRegression'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "533da498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели XGBClassifier = 0.7630605640314378\n",
      "Wall time: 6min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели XGBClassifier =', f_5ML_models_f1(features_train, target_train, features_test, target_test,\n",
    "                                                   df_f1, ' без BERT', 'XGBClassifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7598493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LGBMClassifier = 0.7714790807307011\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LGBMClassifier =', f_5ML_models_f1(features_train, target_train, features_test, target_test,\n",
    "                                                    df_f1, ' без BERT', 'LGBMClassifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a622f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addb8caff129416a90d029e287c73f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели CatBoostClassifier = 0.7694467846110644\n",
      "Wall time: 13min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели CatBoostClassifier =', f_5ML_models_f1(features_train, target_train, features_test, target_test,\n",
    "                                                        df_f1, ' без BERT', 'CatBoostClassifier'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c46f8d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 константной модели = 0.16886083309107522\n",
      "Wall time: 52.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 константной модели =', f_5ML_models_f1(features_train, target_train, features_test, target_test,\n",
    "                                                 df_f1, ' без BERT', 'Константная модель'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55266fce",
   "metadata": {},
   "source": [
    "### Прогнозирование ML-моделей на тестовых выборках, подготовленных с BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9984f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели LinearRegression = 0.6178861788617886\n",
      "Wall time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели LinearRegression =', f_5ML_models_f1(features_train_bert, target_train_bert, features_test_bert,\n",
    "                                                      target_test_bert, df_f1, ' с BERT', 'LogisticRegression'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0acd59a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bbd7235bff4beeb4370be0bd865bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 модели CatBoostClassifier = 0.5659340659340659\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 модели CatBoostClassifier =', f_5ML_models_f1(features_train_bert, target_train_bert, features_test_bert,\n",
    "                                                        target_test_bert, df_f1, ' с BERT', 'CatBoostClassifier',\n",
    "                                                        312, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bd6ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 константной модели = 0.16005291005291006\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('F1 константной модели =', f_5ML_models_f1(features_train_bert, target_train_bert, features_test_bert,\n",
    "                                                 target_test_bert, df_f1, ' с BERT', 'Константная модель'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67891b1c",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab80b3",
   "metadata": {},
   "source": [
    "Таблица значений метрик F1 моделей на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "012b65fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression без BERT</td>\n",
       "      <td>0.754261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBClassifier без BERT</td>\n",
       "      <td>0.763061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier без BERT</td>\n",
       "      <td>0.771479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier без BERT</td>\n",
       "      <td>0.769447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Константная модель без BERT</td>\n",
       "      <td>0.168861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression с BERT</td>\n",
       "      <td>0.617886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoostClassifier с BERT</td>\n",
       "      <td>0.565934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Константная модель с BERT</td>\n",
       "      <td>0.160053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Модель  F1-score\n",
       "0  LogisticRegression без BERT  0.754261\n",
       "1       XGBClassifier без BERT  0.763061\n",
       "2      LGBMClassifier без BERT  0.771479\n",
       "3  CatBoostClassifier без BERT  0.769447\n",
       "4  Константная модель без BERT  0.168861\n",
       "5    LogisticRegression с BERT  0.617886\n",
       "6    CatBoostClassifier с BERT  0.565934\n",
       "7    Константная модель с BERT  0.160053"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f54a2",
   "metadata": {},
   "source": [
    "**По результатам проекта можно сделать следующие выводы:**\n",
    "1. Лучшей ML-моделью для классификации комментариев на положительные или отрицательные является «градиентный бустинг» библиотеки LightGBM, использующая выборки, подготовленные без BERT. Значение метрики F1 на тестовой выборке = 0.77, что соответствует условиям проекта (значение метрики F1 не меньше 0.75).\n",
    "2. Если для компании приоритетом является скорость классификации комментариев, то целесообразно использовать модель «логистическая регрессия». У данной модели время обучения и прогнозирования - около 1.6 с (более чем в 80 раз быстрее, по сравнению с моделями градиентного бустинга), при этом качество предсказания по метрике F1 лишь немного хуже, чем у моделей градиентного бустинга.\n",
    "3. Использование 10000 строк для подготовки выборок с использованием предобученной модели нейронной сети BERT, чтобы значение метрики F1 было не меньше 0.75, недостаточно. При этом,  следует отметить, что подготовка полной выборки с использованием BERT на персональном компьютере занимает около 5 суток.\n",
    "4. Все ML-модели осуществляют прогноз лучше, чем константная модель (F1 = 0.17). Поэтому, применение указанных ML-моделей является оправданным для бизнеса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
